{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  906980\n",
      "Alphabet:  \n",
      " !\"#$%&'()*+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz°³»ÀÇÈÉÊÎÔÖàáâãäçèéêëíîïòóôöøùúûüāćčĒğıōœšеḥ ​‎–—‘’… ∞\n",
      "Alphabet length:  138\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/tinychen.txt\", \"r\") as f:\n",
    "    tinychen = f.read()\n",
    "    \n",
    "print('Dataset length: ', len(tinychen))\n",
    "alphabet = sorted(list(set(tinychen)))\n",
    "print('Alphabet: ', ''.join(alphabet))\n",
    "print('Alphabet length: ', len(alphabet))\n",
    "vocab_size=len(alphabet)\n",
    "itos = {i:s for i,s in enumerate(alphabet)}\n",
    "stoi = {s:i for i,s in itos.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda t: ''.join([itos[tk] for tk in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(tinychen), dtype=torch.long)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x =x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "xb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.48573637008667\n",
      "\n",
      "R*t,é=1Y)OÉ³bÖCëBySRqS_lcœù0…zÊU9?Fy\"Xã+Tp’MÖdUœy+*_û‎Ulœ/o:áX’MBF#K:ğFyx#èH+lÀt,oè,8DÔRjT#òḥ…f;2èX_\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        logits = self.embedding_table(idx)\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.shape[2]), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx, )\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.concat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLM(vocab_size)\n",
    "m = m.to(device)\n",
    "logits, loss = m(xb, yb)\n",
    "print(loss.item())\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "for _ in range(1000):\n",
    "    m.zero_grad(True)\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb,yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5339064598083496\n",
      "\n",
      "M:àTowœ#5ıT0œ–Jwçíğøœč—’ve=∞t89 afVTøf4Kōè%čyíãte,sùlaue2еGGSpdPùSć&yP 7šn8òïòc )…ı‘?2LW–Un=…äx∞:$o³\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch('test')\n",
    "logits, loss = m(x,y)\n",
    "print(loss.item())\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xbow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m wei2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(wei2, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m xbow3 \u001b[38;5;241m=\u001b[39m wei2 \u001b[38;5;241m@\u001b[39m x\n\u001b[0;32m----> 8\u001b[0m torch\u001b[38;5;241m.\u001b[39mallclose(\u001b[43mxbow\u001b[49m, xbow3)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xbow' is not defined"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei2 = torch.zeros((T,T))\n",
    "wei2 = wei2.masked_fill(tril == 0, float('-inf'))\n",
    "wei2 = F.softmax(wei2, 1)\n",
    "xbow3 = wei2 @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = \n",
      "tensor([[4., 6.],\n",
      "        [6., 5.],\n",
      "        [3., 9.]])\n",
      "c = \n",
      "tensor([[4.0000, 6.0000],\n",
      "        [5.0000, 5.5000],\n",
      "        [4.3333, 6.6667]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,0,0], [0.5,0.5,0], [1/3, 1/3, 1/3]])\n",
    "b = torch.randint(0,10, (3,2)).float()\n",
    "c = a @ b\n",
    "print('a = ')\n",
    "print(a)\n",
    "print('b = ')\n",
    "print(b)\n",
    "print('c = ')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.4956e-01,  4.8846e-01,  1.1604e-01,  4.7534e-01, -8.5612e-01,\n",
       "          -1.4982e-01, -3.7018e-01,  1.4848e-01, -2.1831e-01,  5.4938e-01,\n",
       "           9.2951e-01,  1.5742e-01, -4.6831e-01,  4.0962e-01, -6.1533e-01,\n",
       "           2.8312e-01],\n",
       "         [-5.2120e-01,  6.9884e-01, -3.4801e-01,  3.5749e-01, -5.4268e-01,\n",
       "           4.3744e-01, -4.9831e-01,  4.3937e-02, -4.7958e-01, -1.4578e-01,\n",
       "           6.8815e-01,  1.9685e-01, -1.7646e-01,  3.4085e-01, -2.5280e-02,\n",
       "           1.5239e-01],\n",
       "         [-4.0817e-01,  5.1237e-01, -4.8422e-01,  1.0110e-01, -3.0235e-01,\n",
       "           3.8226e-01, -6.2279e-01, -1.6023e-01, -7.2873e-01, -9.7741e-02,\n",
       "           4.4068e-01,  2.6522e-01, -8.0118e-02, -3.0906e-01,  2.0049e-01,\n",
       "           2.9922e-01],\n",
       "         [-1.5727e-01,  6.3299e-01,  6.7453e-02,  2.1275e-02, -1.9719e-01,\n",
       "           2.4416e-01, -8.0245e-01, -5.9525e-01, -4.6648e-01, -1.5551e-01,\n",
       "           5.2784e-01,  7.4219e-01,  2.7955e-01, -4.0823e-01, -3.8099e-01,\n",
       "           1.8801e-01],\n",
       "         [-3.8921e-01,  4.6713e-01, -9.2777e-02,  1.2760e-01, -3.7260e-01,\n",
       "           2.4475e-01, -3.3892e-01, -5.3280e-01, -5.0073e-01,  8.4573e-03,\n",
       "           4.8158e-01,  4.7116e-01,  1.4542e-03, -3.0916e-01,  1.7440e-01,\n",
       "           2.0601e-01],\n",
       "         [-2.4651e-01,  6.4077e-02, -1.0026e-01,  1.0701e-01, -2.7431e-01,\n",
       "           2.0787e-01, -3.5613e-01, -1.9530e-01, -3.4291e-01, -5.0894e-02,\n",
       "           4.1397e-01,  1.6310e-01, -1.2966e-02, -6.6347e-02, -5.7819e-02,\n",
       "           3.0530e-01],\n",
       "         [-2.2777e-01,  3.8339e-01,  8.4473e-02,  1.2711e-01, -3.0740e-01,\n",
       "           1.6973e-01, -4.1620e-01, -3.1135e-01, -3.5990e-01, -5.5637e-02,\n",
       "           4.8462e-01,  5.1027e-01,  1.8200e-01, -5.3985e-02, -1.9540e-01,\n",
       "           1.4310e-01],\n",
       "         [-3.2186e-01,  3.0184e-02,  7.0328e-02,  1.0031e-01, -3.2427e-01,\n",
       "           6.3355e-02, -1.3224e-02, -1.6115e-01, -3.5661e-01,  1.2832e-01,\n",
       "           2.4682e-01,  2.6140e-01,  1.3723e-02, -1.3380e-01,  2.8510e-01,\n",
       "           2.1198e-01]],\n",
       "\n",
       "        [[-2.5045e-01, -7.0761e-01, -2.9918e-01,  9.7033e-02,  9.6560e-02,\n",
       "           4.0145e-01, -3.0713e-01,  4.1527e-01, -5.6434e-01, -1.5518e-01,\n",
       "          -3.8921e-01,  3.7906e-01,  1.8637e-01,  4.0863e-01, -8.8764e-02,\n",
       "           6.1639e-01],\n",
       "         [ 4.0261e-02, -1.1338e-01,  4.5030e-02, -2.4532e-01,  4.2480e-01,\n",
       "           1.3296e-01, -1.2173e-01,  8.3186e-02, -5.8436e-02, -4.4060e-01,\n",
       "          -3.2301e-01,  2.1948e-01,  2.3172e-01,  2.6652e-01,  2.3728e-01,\n",
       "           1.5611e-01],\n",
       "         [-8.1597e-02,  3.1184e-01, -1.8395e-01, -1.4672e-01,  4.2190e-01,\n",
       "          -1.2984e-01, -9.4350e-02, -2.1134e-01, -2.4738e-01, -3.9439e-01,\n",
       "           7.7747e-03,  2.3386e-01,  1.9552e-01, -3.4954e-02, -3.0528e-01,\n",
       "           2.0108e-01],\n",
       "         [ 1.1087e-01,  3.7584e-01, -2.2649e-01, -7.9251e-02,  3.2593e-01,\n",
       "          -2.3904e-01,  8.2385e-03, -1.9107e-01, -2.1747e-01, -3.9833e-01,\n",
       "           2.8212e-02,  2.0272e-01,  2.2769e-02, -1.1782e-01,  6.8535e-02,\n",
       "           1.2860e-01],\n",
       "         [ 2.8042e-02,  2.6308e-01, -1.8030e-01, -3.9860e-02,  1.2996e-01,\n",
       "          -3.8980e-01,  5.8979e-02, -2.1010e-01, -4.4831e-01, -2.2080e-01,\n",
       "           1.1514e-01,  2.2535e-01, -2.7051e-02, -2.0094e-01, -2.5072e-01,\n",
       "           3.4433e-01],\n",
       "         [ 1.0972e-01,  2.4016e-01,  1.1507e-01, -9.0602e-02,  4.0397e-01,\n",
       "          -1.1189e-01,  3.1868e-01, -1.1129e-01,  1.3914e-01, -4.5685e-01,\n",
       "           7.8253e-03, -3.4565e-02, -1.0118e-01,  1.0666e-01,  2.6716e-01,\n",
       "           8.9569e-02],\n",
       "         [-8.9933e-02,  3.2960e-01, -1.9773e-01,  2.4057e-01,  3.6743e-01,\n",
       "          -4.5546e-03,  4.4535e-01, -9.9357e-02, -5.7699e-02, -3.1540e-01,\n",
       "           2.9379e-01, -6.2060e-02, -6.8809e-02,  2.6493e-01, -2.9543e-01,\n",
       "           2.0372e-01],\n",
       "         [-1.4376e-01,  1.5326e-01, -8.8191e-02,  1.4781e-01,  1.6066e-01,\n",
       "           1.8515e-02,  4.2854e-01, -3.6760e-02, -2.9165e-02, -2.7455e-01,\n",
       "           2.5755e-01, -1.3954e-01, -5.4664e-02,  3.3982e-01, -1.7653e-01,\n",
       "           2.7830e-01]],\n",
       "\n",
       "        [[-2.7289e-01, -1.0145e+00,  1.6892e-01,  1.4716e-01,  2.4570e-01,\n",
       "          -2.9639e-01, -5.0299e-01,  4.0183e-01, -3.2432e-01,  3.1234e-02,\n",
       "           4.9338e-01, -6.7195e-01,  9.8131e-02,  6.5058e-02,  3.3334e-01,\n",
       "           9.4767e-01],\n",
       "         [-2.2630e-01, -5.1666e-01, -3.0894e-01,  1.3235e-01,  2.2934e-01,\n",
       "           1.1049e-01, -5.8769e-01,  4.9103e-01, -3.8480e-01, -2.6887e-01,\n",
       "           3.4229e-01, -2.6941e-01,  4.8112e-03,  8.9542e-02,  2.9021e-01,\n",
       "           6.1328e-01],\n",
       "         [-4.2987e-02,  2.0322e-01, -7.7391e-01,  1.3509e-01,  5.2944e-02,\n",
       "           3.1641e-01, -2.0534e-01,  5.1480e-01, -3.9947e-01, -5.1200e-01,\n",
       "           3.5802e-01, -1.5715e-02, -1.3368e-01,  1.4617e-01,  2.4959e-01,\n",
       "           2.6680e-01],\n",
       "         [-5.8954e-02,  3.1394e-01, -3.5043e-01,  2.1967e-01, -1.6700e-01,\n",
       "           1.6080e-01,  1.6684e-01,  1.7208e-01, -2.7426e-02, -4.2116e-02,\n",
       "           4.0072e-01, -7.1576e-02, -2.1190e-01, -4.6058e-02,  2.8677e-02,\n",
       "           8.2022e-02],\n",
       "         [-1.3946e-01,  3.7329e-01, -4.5714e-01,  1.9576e-01, -1.8723e-01,\n",
       "           8.1160e-02,  4.5407e-01,  5.8665e-02,  6.9217e-02, -4.8044e-02,\n",
       "           3.8005e-01,  1.8244e-01, -1.9033e-01,  1.9175e-01,  8.0543e-02,\n",
       "           3.6732e-02],\n",
       "         [-3.6074e-01,  4.1657e-02, -3.0153e-01,  2.1309e-01,  1.3064e-02,\n",
       "           3.7635e-01, -4.5074e-01,  1.5161e-01, -4.3875e-02,  2.1491e-02,\n",
       "           6.0556e-02,  2.5990e-01, -1.8326e-02,  5.2163e-02, -5.6470e-02,\n",
       "           1.3696e-02],\n",
       "         [-2.8520e-01,  1.4268e-01, -5.2282e-01,  2.9143e-01, -4.9353e-02,\n",
       "           3.5536e-01, -1.8521e-01,  1.8771e-01, -1.4870e-01, -3.7754e-02,\n",
       "           2.8885e-01, -1.3699e-01, -1.6878e-01,  1.0888e-01,  1.2868e-01,\n",
       "           2.9125e-02],\n",
       "         [-2.7313e-01, -5.1413e-02, -3.9033e-01,  2.7122e-01,  1.2472e-01,\n",
       "           2.6684e-01, -2.6711e-01,  9.2124e-02,  1.7881e-02, -1.0570e-01,\n",
       "           2.9644e-01, -2.4275e-01, -2.2542e-01,  9.3469e-02,  1.8408e-01,\n",
       "           7.6676e-02]],\n",
       "\n",
       "        [[-1.5518e-01, -7.8771e-02,  7.1563e-01, -1.6292e-02,  5.4240e-01,\n",
       "           4.9739e-02,  3.3667e-01, -6.6613e-01, -6.5248e-01,  3.3818e-01,\n",
       "           1.9652e-01, -1.9766e-01,  7.3928e-02, -1.5543e-01, -3.7675e-01,\n",
       "          -3.2369e-01],\n",
       "         [ 1.5350e-01, -1.0647e-01,  6.8904e-01, -7.3929e-02,  2.7423e-03,\n",
       "          -1.8758e-01,  4.9560e-01, -6.1567e-01,  1.7653e-01, -1.9354e-02,\n",
       "          -7.2954e-02, -1.1964e-01, -2.2714e-01, -3.4569e-03, -3.5208e-02,\n",
       "          -9.8927e-02],\n",
       "         [ 1.2667e-01, -1.5069e-01,  6.5585e-01, -1.8739e-01,  7.4956e-02,\n",
       "          -1.2831e-01,  3.0054e-01, -3.7839e-01,  1.6535e-01,  3.8435e-02,\n",
       "          -2.8080e-01, -1.7927e-01, -1.0764e-01, -4.5092e-02, -8.2691e-04,\n",
       "          -8.0823e-02],\n",
       "         [ 2.2248e-01,  1.9796e-02,  4.1841e-01, -3.0020e-01, -2.3116e-01,\n",
       "          -2.9333e-02,  3.9987e-01, -2.5076e-01,  3.4913e-01, -2.2847e-01,\n",
       "          -3.2984e-01, -1.9898e-01, -1.4436e-01,  1.3595e-01,  8.1280e-03,\n",
       "           8.5491e-02],\n",
       "         [ 2.9411e-02,  1.3307e-01,  3.7558e-01, -2.8945e-01, -2.9244e-01,\n",
       "           2.3014e-01,  3.7229e-01, -3.0659e-01,  8.6417e-02, -2.9951e-01,\n",
       "          -1.2693e-01, -1.5799e-01, -8.1099e-02,  1.1743e-01, -6.6296e-02,\n",
       "           8.5460e-02],\n",
       "         [-3.3983e-01, -3.7943e-02,  2.7221e-01, -3.1786e-01, -1.0182e-01,\n",
       "           3.6720e-01,  3.9000e-01, -1.6640e-01, -6.3113e-02, -1.8585e-01,\n",
       "           2.5899e-02, -3.4193e-01, -2.4068e-01,  4.2588e-01, -5.1136e-02,\n",
       "           2.9279e-01],\n",
       "         [-5.9747e-02,  2.2973e-02,  2.7691e-01, -3.7036e-01, -1.5141e-01,\n",
       "           2.5298e-01,  1.3634e-01, -1.3633e-01,  3.6701e-02, -1.7390e-01,\n",
       "          -3.1188e-01, -2.2208e-01,  3.6074e-02,  8.1517e-02,  8.1643e-02,\n",
       "           1.1196e-02],\n",
       "         [-1.2471e-01,  2.2040e-01,  1.3857e-01, -3.2262e-01, -9.9400e-02,\n",
       "           1.7631e-01,  2.8000e-01, -1.8526e-01,  6.5323e-02, -1.8979e-01,\n",
       "          -1.0541e-01, -1.5689e-01, -1.2793e-01,  1.2397e-01,  2.0457e-01,\n",
       "           5.9829e-02]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C = 4, 8, 32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0,float('-inf'))\n",
    "wei = F.softmax(wei, -1)\n",
    "out = wei @ value(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS available: True\n",
      "Current device: mps\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.backends.cuda' has no attribute 'is_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs MPS available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtorch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.backends.cuda' has no attribute 'is_available'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Is MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"Current device: {torch.device('mps' if torch.backends.mps.is_available() else 'cpu')}\")\n",
    "print(torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
